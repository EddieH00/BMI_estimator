{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/eddieh00/UCSD/ms/ece228/bmi_model/facenet/src')\n",
    "import facenet\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0 / np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1 / std_adj)\n",
    "    return y\n",
    "\n",
    "def load_and_preprocess_image(image_path, image_size):\n",
    "    try:\n",
    "        # Load image\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize(image_size)\n",
    "        image = np.array(image)\n",
    "\n",
    "        # Preprocess the image\n",
    "        image = prewhiten(image)\n",
    "\n",
    "        return image\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found: \" + str(image_path))\n",
    "        return None\n",
    "\n",
    "def generate_embeddings(image_paths, labels, model_path, image_size):\n",
    "    assert len(image_paths) == len(labels), \"Number of image paths and labels must be the same.\"\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Load the facenet model\n",
    "            facenet.load_model(model_path)\n",
    "\n",
    "            # Get input and output tensors\n",
    "            input_tensor = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            output_tensor = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_tensor = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "            # Generate embeddings and matching labels\n",
    "            embeddings = []\n",
    "            matching_labels = []\n",
    "            for image_path, label in zip(image_paths, labels):\n",
    "                image = load_and_preprocess_image(image_path, image_size)\n",
    "                if image is not None:\n",
    "                    image = np.expand_dims(image, axis=0)\n",
    "                    emb = sess.run(output_tensor, feed_dict={input_tensor: image, phase_train_tensor: False})\n",
    "                    embeddings.append(emb.flatten())\n",
    "                    matching_labels.append(label)\n",
    "\n",
    "            embeddings = np.array(embeddings)\n",
    "\n",
    "    return embeddings, matching_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /home/eddieh00/UCSD/ms/ece228/bmi_model/facenet/best_facenet_model\n",
      "Metagraph file: model-20180402-114759.meta\n",
      "Checkpoint file: model-20180402-114759.ckpt-275\n",
      "INFO:tensorflow:Restoring parameters from /home/eddieh00/UCSD/ms/ece228/bmi_model/facenet/best_facenet_model/model-20180402-114759.ckpt-275\n",
      "File not found: /home/eddieh00/UCSD/ms/ece228/bmi_model/data/faces_precropped/_daewon_(lee_daewon 대원).jpg\n",
      "File not found: /home/eddieh00/UCSD/ms/ece228/bmi_model/data/faces_precropped/_damon_(qiū_báo_hàn).jpg\n",
      "File not found: /home/eddieh00/UCSD/ms/ece228/bmi_model/data/faces_precropped/_ha_bin_(ha_bin 하빈).jpg\n",
      "File not found: /home/eddieh00/UCSD/ms/ece228/bmi_model/data/faces_precropped/_harang_(park_ha_rang 하랑).jpg\n",
      "File not found: /home/eddieh00/UCSD/ms/ece228/bmi_model/data/faces_precropped/_manny_(xiào_dōngchéng).jpg\n",
      "File not found: /home/eddieh00/UCSD/ms/ece228/bmi_model/data/faces_precropped/_xin_(wáng_xīnyû).jpg\n",
      "File not found: /home/eddieh00/UCSD/ms/ece228/bmi_model/data/faces_precropped/aboutu_victor_han_(victor_han_baccic_galvão).jpg\n",
      "File not found: /home/eddieh00/UCSD/ms/ece228/bmi_model/data/faces_precropped/high4_alex_(alexsander_kim_알렉스_김)).jpg\n"
     ]
    }
   ],
   "source": [
    "from data_model import DataGenerator\n",
    "base_path = '/home/eddieh00/UCSD/ms/ece228/bmi_model/data/faces_precropped'\n",
    "csv_file = 'faces_precropped.csv'  # Replace with your CSV file name\n",
    "model_path = '/home/eddieh00/UCSD/ms/ece228/bmi_model/facenet/best_facenet_model'\n",
    "image_size = (160, 160)\n",
    "batch_size = 32\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(os.path.join(base_path, csv_file))\n",
    "image_paths = [os.path.join(base_path, filename) for filename in df['bookid']]\n",
    "labels = np.array(df['bmi'])\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings, labels = generate_embeddings(image_paths, labels, model_path, image_size)\n",
    "\n",
    "\n",
    "# Split the data into training, test, and validation sets\n",
    "train_embeddings, test_embeddings, train_labels, test_labels = train_test_split(\n",
    "    embeddings, labels, test_size=0.2, random_state=42)\n",
    "test_embeddings, val_embeddings, test_labels, val_labels = train_test_split(\n",
    "    test_embeddings, test_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create data loader objects\n",
    "train_data_loader = DataGenerator(train_embeddings, train_labels, batch_size)\n",
    "test_data_loader = DataGenerator(test_embeddings, test_labels, batch_size)\n",
    "val_data_loader = DataGenerator(val_embeddings, val_labels, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmi_model import BMI_Estimator\n",
    "\n",
    "model = BMI_Estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1c23a81c68fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'epochs'"
     ]
    }
   ],
   "source": [
    "model.train(train_data_loader, epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece228",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
